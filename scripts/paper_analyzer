#! /usr/bin/env python3
"""
paper_analyzer script

analyze new papers from database, and assign a score based on keywords
"""

# % IMPORTS

import json
import re
import feedparser as fp
from pathlib import Path
from time import mktime
from datetime import datetime

# % LOCAL IMPORT

from sql_connect import sqlconnector

# % SETTINGS

DIR = Path(__file__).parents[0]  # returns the script directory
DB_PATH = DIR / ".." / "db" / "paperwatch.sqlite"


# % FUNCTIONS


def _explode_and_trim(str_in):
    if str_in is None:
        return [""]
    list_out = str_in.split(",")
    list_out = [e.strip() for e in list_out]
    return list_out


@sqlconnector(DB_PATH)
def load_keywords(db_con):
    write_log("analysis", "load keywords")
    # -- prepare sql request
    fields = ["category", "short_name", "keywords"]
    sql_req = f"select {",".join(fields)} from keywords;"
    cur = db_con.cursor()
    # -- store results in dictionnary
    keywords = []
    for row in cur.execute(sql_req):
        new_cat = {k: v for k, v in zip(fields, row)}
        new_cat["keywords"] = _explode_and_trim(new_cat["keywords"])
        keywords.append(new_cat)
    return keywords


@sqlconnector(DB_PATH)
def load_authors(db_con):
    write_log("analysis", "load authors")
    # -- prepare sql request
    fields = ["name", "tags"]
    sql_req = f"select {",".join(fields)} from authors;"
    cur = db_con.cursor()
    # -- store results in dictionnary
    authors = []
    for row in cur.execute(sql_req):
        new_auth = {k: v for k, v in zip(fields, row)}
        new_auth["tags"] = _explode_and_trim(new_auth["tags"])
        authors.append(new_auth)
    return authors


@sqlconnector(DB_PATH)
def fetch_new_papers(db_con):
    write_log("analysis", "fetch new papers")
    # -- prepare sql request
    fields = ["author", "title", "summary", "id"]
    sql_req = f"select {",".join(fields)} from papers where analyzed=False;"
    # -- store results
    papers = []
    for row in db_con.execute(sql_req):
        new_paper = {k: v for k, v in zip(fields, row)}
        papers.append(new_paper)
    return papers


def analyze_papers(papers, keywords, authors, analysis_id):
    write_log("analysis", "analyze papers")
    results = {}
    for p in papers:
        # -- get data
        paper_aut = json.loads(p["author"])
        title = p["title"]
        summary = p["summary"]
        # -- init result
        keywords_score = 0
        keywords_tags = set()
        authors_score = 0
        authors_tags = set()
        score_detail = {}
        followed_authors = set()
        # -- analyze authors
        author_list_formatted = []
        for aut in paper_aut:
            for followed_aut in authors:
                if followed_aut["name"].lower() in aut.lower():
                    authors_score += 1
                    followed_authors.add(aut)
                    authors_tags |= {t for t in followed_aut["tags"]}
                    aut = "**" + aut + "**"
            author_list_formatted.append(aut)
        author_display = ", ".join(author_list_formatted)
        # -- search for keywords
        for cat in keywords:
            name = cat["category"]
            score_detail[name] = 0
            for kw in cat["keywords"]:
                if kw.lower() in summary.lower():
                    score_detail[name] += 1
                    keywords_score += 1
                    keywords_tags.add(name)
                if kw.lower() in title.lower():
                    score_detail[name] += 1
                    keywords_score += 1
                    keywords_tags.add(name)

        # -- total score
        total_score = keywords_score + authors_score

        # -- convert sets
        keywords_tags = [k for k in keywords_tags]
        authors_tags = [a for a in authors_tags]
        followed_authors = [a for a in followed_authors]
        # -- store results
        res = {
            "analysis_id": analysis_id,
            "total_score": total_score,
            "keywords_score": keywords_score,
            "keywords_tags": json.dumps(keywords_tags),
            "authors_score": authors_score,
            "authors_tags": json.dumps(authors_tags),
            "score_detail": json.dumps(score_detail),
            "followed_authors": json.dumps(followed_authors),
            "selected": total_score > 0,
            "analyzed": True,
            "author_display": author_display,
        }

        results[p["id"]] = res

    return results


def _insert_analysis_result(db_con, id, res):
    # -- prepare request
    req_pattern = "UPDATE papers SET {} where id=?;"
    values_str = ",".join([f"{k} = ?" for k in res.keys()])
    values = list(res.values()) + [
        id,
    ]
    req = req_pattern.format(values_str)
    # -- post
    try:
        db_con.execute(req, values)
    except Exception as e:
        print(e)
        return 0
    return 1

@sqlconnector(DB_PATH)
def store_results(db_con, results):
    """
    Store analysis result in database
    """
    write_log("analysis", "store papers")
    # -- prepare counter
    papers_analyzed = 0
    papers_selected = 0

    # -- iterate
    for id, res in results.items():
        if _insert_analysis_result(db_con, id, res):
            papers_analyzed += 1
            papers_selected += res["selected"]

    # -- return result
    res = {}
    res["papers_analyzed"] = papers_analyzed
    res["papers_selected"] = papers_selected
    res["success"] = True
    return res

@sqlconnector(DB_PATH)
def create_analysis_entry(db_con):
    """
    creates an entry in the analysis table
    and returns the id
    """
    write_log("analysis", "create analysis entry")
    # -- prepare request
    sql_req = f"INSERT INTO analysis (success) values (false);"
    # -- insert new entry with feed info
    db_con.execute(sql_req)
    # -- get last entry
    res = db_con.execute("select max(id) from analysis;")
    last_id = res.fetchone()[0]
    return last_id


@sqlconnector(DB_PATH)
def store_analysis_results(db_con, result, analysis_id):
    """
    store analysis results in the analysis table
    """
    write_log("analysis", "store analysis result")
    req = "UPDATE analysis SET {} WHERE id = ?;"
    values_str = ",".join([f"{k} = ?" for k in result.keys()])
    values = list(result.values()) + [
        analysis_id,
    ]
    req = req.format(values_str)
    db_con.execute(req, values)


# % FOR DEBUGGING


@sqlconnector(DB_PATH)
def write_log(db_con, action, details="", error=False):
    db_con.execute(
        "INSERT INTO log(action, details, error) values(?, ?, ?)",
        (action, details, error),
    )


# % MAIN ROUTINE


def main():
    write_log("analysis", "--- starting analysis ---")
    # -- 1 - get keywords and authors
    keywords = load_keywords()
    authors = load_authors()
    # -- 2 - add a analysis entry
    analysis_id = create_analysis_entry()
    # -- 3 - fetch new papers
    papers = fetch_new_papers()
    # -- 4 - analyze papers
    results = analyze_papers(papers, keywords, authors, analysis_id)
    # -- 5 - update papers table
    res = store_results(results)
    # -- 6 - store result
    store_analysis_results(res, analysis_id)
    # -- DONE
    write_log("analysis", "--- success ---")


# % EXECUTION
if __name__ == "__main__":
    try:
        main()
    except Exception as e:
        write_log("analysis", str(e), error=True)
        raise e
